% sample text
\chapter{Conclusion}\label{ch:conclusion}
\paragraph We proposed PPO-Beta with dual channel architecture to
predict both alpha and beta values for environment with 2
bounded continuous action space.
We chose PPO as RL
algorithm for training the agent.
After testing in traffic
intersection environment, the agent can learn to be more careful when crossing the intersection than agent trained with
standard Gaussian implementation.
We also see that the
training performance hardly drops in our implementation.
In the future, we are going to extend to multi-agent version
with more complex agentsâ€™ interaction and testing with real
street data capture from drone footage such as the data
provided by German transportation companies~\cite{bock2019ind} to see how
the agents deal with real situations.
