@misc{chen2020interpretable,
    title={Interpretable End-to-end Urban Autonomous Driving with Latent Deep Reinforcement Learning},
    author={J. Chen and S. E. Li and M. Tomizuka},
    year={2020},
    eprint={2001.08726},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}

@article{peng2021end,
    title={End-to-End Autonomous Driving Through Dueling Double Deep Q-Network},
    author={B. Peng and et al.},
    journal={Automotive Innovation},
    volume={4},
    number={3},
    pages={328--337},
    year={2021},
    month={8},
    doi={10.1007/s42154-021-00151-3}
}

@misc{capasso2021endtoend,
    title={End-to-End Intersection Handling using Multi-Agent Deep Reinforcement Learning},
    author={A. P. Capasso and P. Maramotti and A. Dell’Eva and A. Broggi},
    year={2021},
    eprint={2104.13617},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@misc{xu2016endtoend,
    title={End-to-end Learning of Driving Models from Large-scale Video Datasets},
    author={H. Xu and Y. Gao and F. Yu and T. Darrell},
    year={2016},
    eprint={1612.01079},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}

@misc{toromanoff2019endtoend,
    title={End-to-End Model-Free Reinforcement Learning for Urban Driving using Implicit Affordances},
    author={M. Toromanoff and E. Wirbel and F. Moutarde},
    year={2019},
    archivePrefix={arXiv},
    eprint={1911.10868},
    primaryClass={cs.RO}
}

@misc{mnih2016asynchronous,
    title={Asynchronous Methods for Deep Reinforcement Learning},
    author={V. Mnih and et al.},
    year={2016},
    eprint={1602.01783},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{schulman2017proximal,
    title={Proximal Policy Optimization Algorithms},
    author={J. Schulman and F. Wolski and P. Dhariwal and A. Radford and O. Klimov},
    year={2017},
    eprint={1707.06347},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{schulman2015trust,
    title={Trust Region Policy Optimization},
    author={J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
    year={2015},
    eprint={1502.05477},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{peng2021learning,
    title={Learning to Simulate Self-Driven Particles System with Coordinated Policy Optimization},
    author={Z. Peng and Q. Li and K. M. Hui and C. Liu and B. Zhou},
    year={2021},
    eprint={2110.13827},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@misc{yang2018mean,
    title={Mean Field Multi-Agent Reinforcement Learning},
    author={Y. Yang and R. Luo and M. Li and M. Zhou and W. Zhang and J. Wang},
    year={2018},
    eprint={1802.05438},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{terry2020pettingzoo,
    title={PettingZoo: Gym for Multi-Agent Reinforcement Learning},
    author={J. K. Terry and et al.},
    year={2020},
    eprint={2009.14471},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{wu2020cooperative,
    title={Cooperative Multiagent Deep Deterministic Policy Gradient (CoMADDPG) for Intelligent Connected Transportation with Unsignalized Intersection},
    author={T. Wu and M. Jiang and L. Zhang},
    journal={Math Probl Eng},
    volume={2020},
    year={2020},
    doi={10.1155/2020/1820527}
}

@misc{petrazzini2021proximal,
    title={Proximal Policy Optimization with Continuous Bounded Action Space via the Beta Distribution},
    author={I. G. B. Petrazzini and E. A. Antonelo},
    year={2021},
    eprint={2111.02202},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{lee2021investigating,
    title={Investigating the state of connected and autonomous vehicles: A literature Review},
    author={K. M. Lee and S. G. Subramanian and M. Crowley},
    year={2021},
    eprint={2111.01100},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}

@article{yang2022inductive,
    title={An inductive heterogeneous graph attention-based multi-agent deep graph infomax algorithm for adaptive traffic signal control},
    author={S. Yang and B. Yang},
    journal={Information Fusion},
    volume={88},
    pages={249--262},
    year={2022},
    month={12},
    doi={10.1016/j.inffus.2022.08.001}
}

@article{wang2021adaptive,
    title={Adaptive Traffic Signal Control for large-scale scenario with Cooperative Group-based Multi-agent reinforcement learning},
    author={T. Wang and J. Cao and A. Hussain},
    journal={Transp Res Part C Emerg Technol},
    volume={125},
    year={2021},
    month={4},
    doi={10.1016/j.trc.2021.103046}
}

@article{essa2020selflearning,
    title={Self-learning adaptive traffic signal control for real-time safety optimization},
    author={M. Essa and T. Sayed},
    journal={Accid Anal Prev},
    volume={146},
    year={2020},
    month={10},
    doi={10.1016/j.aap.2020.105713}
}

@inproceedings{shiwakoti2020investigating,
    title={Investigating the state of connected and autonomous vehicles: A literature Review},
    author={N. Shiwakoti and P. Stasinopoulos and F. Fedele},
    booktitle={Transportation Research Procedia},
    year={2020},
    pages={870--882},
    doi={10.1016/j.trpro.2020.08.101}
}
@article{li2021planning,
    title={Planning and Decision-making for Connected Autonomous Vehicles at Road Intersections: A Review},
    author={S. Li and K. Shu and C. Chen and D. Cao},
    journal={Chinese Journal of Mechanical Engineering},
    volume={34},
    pages={133},
    year={2021},
    doi={10.1186/s10033-021-00639-3}
}

@misc{gunarathna2022intelligent,
    title={Intelligent Autonomous Intersection Management},
    author={U. Gunarathna and S. Karunasekara and R. Borovica-Gajic and E. Tanin},
    year={2022},
    eprint={2202.04224},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}

@inproceedings{qian2017autonomous,
    title={Autonomous Intersection Management systems: criteria, implementation and evaluation; Autonomous Intersection Management systems: criteria, implementation and evaluation},
    author={X. Qian and F. Altché and J. Grégoire and A. De and L. Fortelle},
    year={2017},
    doi={10.1049/iet-its.2016.0043}
}

@inproceedings{chen2019intersection,
    title={Intersection Crossing for Autonomous Vehicles based on Deep Reinforcement Learning},
    author={W.-L. Chen and K.-H. Lee and P.-A. Hsiung},
    booktitle={2019 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)},
    year={2019},
    pages={1--2},
    doi={10.1109/ICCE-TW46550.2019.8991738}
}

@book{sutton2018reinforcement,
    title={Reinforcement Learning: An Introduction},
    author={R. S. Sutton and A. G. Barto},
    year={2018},
    publisher={MIT Press}
}

@misc{johanson2021emergent,
    title={Emergent Social Learning via Multi-agent Reinforcement Learning},
    author={M. B. Johanson and E. Hughes and F. Timbers and J. Z. Leibo},
    year={2021},
    eprint={2105.06760},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{tang2020towards,
    title={Towards Learning Multi-agent Negotiations via Self-Play},
    author={Y. C. Tang},
    year={2020},
    eprint={2001.10208},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{oroojlooyjadid2019review,
    title={A Review of Cooperative Multi-Agent Deep Reinforcement Learning},
    author={A. OroojlooyJadid and D. Hajinezhad},
    year={2019},
    eprint={1908.03963},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@book{siekmann1998agent,
    title={Agent and Multi-Agent Systems: Technologies and Applications},
    author={J. Siekmann and W. Wahlster},
    year={1998},
    publisher={Springer}
}

@misc{zhou2020smarts,
    title={SMARTS: Scalable Multi-Agent Reinforcement Learning Training School for Autonomous Driving},
    author={M. Zhou and et al.},
    year={2020},
    eprint={2010.09776},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@misc{zhang2019multiagent,
    title={Multi-Agent Reinforcement Learning: A Selective Overview of Theories and Algorithms},
    author={K. Zhang and Z. Yang and T. Başar},
    year={2019},
    eprint={1911.10635},
    archivePrefix={arXiv},
    primaryClass={cs.MA}
}

@misc{baker2019emergent,
    title={Emergent Tool Use From Multi-Agent Autocurricula},
    author={B. Baker and et al.},
    year={2019},
    eprint={1909.07528},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{johanson2022emergent,
    title={Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning},
    author={M. B. Johanson and E. Hughes and F. Timbers and J. Z. Leibo},
    year={2022},
    eprint={2205.06760},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{baby2022analysis,
    title={Analysis of Emergent Behavior in Multi Agent Environments using Deep Reinforcement Learning},
    author={S. A. Baby and L. Li and A. Pokle},
    year={2022},
    eprint={},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{mnih2015humanlevel,
    title={Human-level control through deep reinforcement learning},
    author={V. Mnih and et al.},
    journal={Nature},
    volume={518},
    number={7540},
    pages={529--533},
    year={2015},
    doi={10.1038/nature14236}
}

@misc{paszke2019pytorch,
    title={PyTorch: An Imperative Style, High-Performance Deep Learning Library},
    author={A. Paszke and et al.},
    year={2019},
    eprint={1912.01703},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{li2021metadrive,
    title={MetaDrive: Composing Diverse Driving Scenarios for Generalizable Reinforcement Learning},
    author={Q. Li and Z. Peng and L. Feng and Q. Zhang and Z. Xue and B. Zhou},
    year={2021},
    note={Available online at: \url{https://metadriverse.github.io/metadrive}}
}

@misc{brockman2016openai,
    title={OpenAI Gym},
    author={G. Brockman and et al.},
    year={2016},
    eprint={1606.01540},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{bock2019ind,
    title={The inD Dataset: A Drone Dataset of Naturalistic Road User Trajectories at German Intersections},
    author={J. Bock and R. Krajewski and T. Moers and S. Runde and L. Vater and L. Eckstein},
    year={2019},
    eprint={1911.07602},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
