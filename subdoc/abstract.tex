\begin{e-abstract}
This paper addresses the ongoing challenge of enabling autonomous vehicles to safely and efficiently cross intersections, necessitating advanced training techniques.
In order to facilitate large-scale training, the utilization of multi-agent reinforcement methods typically involves simplifying agent policy architectures and placing greater emphasis on estimation.
To this end, our study proposes a novel multi-agent policy gradient method for training agents within unsignalized intersection environments, employing a straightforward centralized learning framework and decentralized execution.
This research places particular emphasis on optimizing agent policy architectures, with a key focus on the application of Beta distributions.
We demonstrate that this approach yields superior stability and enhanced rewards compared to conventional algorithms utilizing Gaussian distributions.
\end{e-abstract}
